{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from 'D:\\\\drive\\\\MyDriveBackup\\\\9.Semester\\\\Masterarbeit\\\\masterarbeit - git\\\\Käferbäume\\\\Unet detect trees\\\\model.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload  # Python 3.4+ only.\n",
    "import data\n",
    "import model as model_functions\n",
    "\n",
    "reload(data)\n",
    "reload(model_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 256#128 #256\n",
    "HEIGHT = 256#128 #256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(input_size=(WIDTH,HEIGHT,3), nr_classes=len(COLOR_DICT))\n",
    "# model.load_weights('../../../Models/detect-tree/multi classes 128 - 256/4th-run-weights-improvement-20-0.0544.h5')\n",
    "model.load_weights('../../../Models/detect-tree/5th-run-128-256-weights-improvement-18-0.0959.h5') # new\n",
    "\n",
    "# load_model('../../../Models/detect-tree/multi classes 128 - 256/4th-run-weights-improvement-20-0.0544.h5', custom_objects={'softMaxAxis1': softMaxAxis1, 'mean_io_u_13': tf.keras.metrics.MeanIoU})#, 'mean_io_u_13': tf.keras.metrics.MeanIoU, 'MeanIoU': tf.keras.metrics.MeanIoU})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 256, 256, 64) 1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 128, 128, 128 147584      conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 512)  0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 1024) 4719616     max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 1024) 0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 1024) 0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 1024) 0           dropout_3[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 512)  0           conv2d_30[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 256 0           conv2d_28[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 128, 128, 128 295040      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 128, 128, 128 147584      conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 256, 256, 128 0           conv2d_26[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 256, 256, 32) 18464       conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 256, 256, 2)  66          conv2d_47[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,050,210\n",
      "Trainable params: 31,050,210\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process all images in a folder + subfolders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = \"../../../Data/Borkenkaefer/data\"\n",
    "# save_masks_path = \"../../../Data/Borkenkaefer/data_trunc_detected_masks\"\n",
    "# save_cropped_path = \"../../../Data/Borkenkaefer/data_trunc_detected_cropped\"\n",
    "# save_multiplied_path = \"../../../Data/Borkenkaefer/data_trunc_detected_multiplied\"\n",
    "\n",
    "folder_path = \"../../../Data/BFW/filtered\"\n",
    "save_masks_path = \"../../../Data/BFW/data_trunc_detected_masks\"\n",
    "save_cropped_path = \"../../../Data/BFW/data_trunc_detected_cropped\"\n",
    "save_multiplied_path = \"../../../Data/BFW/data_trunc_detected_multiplied\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = np.argmax(pred_mask, axis=-1)\n",
    "#     pred_mask = pred_mask[..., np.newaxis]\n",
    "    color_label_matrix = data.get_color_label_matrix(pred_mask[0])\n",
    "    return color_label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import interpolation\n",
    "\n",
    "def crop_image(file_name, mask):\n",
    "    # this method crops left and right from the image such that only the trunk is left\n",
    "    full_size_image = image.load_img(file_name)\n",
    "    \n",
    "    # resize the mask to match the original image size using interpolation\n",
    "    img_width = full_size_image.width\n",
    "    img_height = full_size_image.height\n",
    "    mask = interpolation.zoom(mask, [img_height/mask.shape[0], img_width/mask.shape[1]])\n",
    "    \n",
    "    # keep columns, which have an avg of more than x%\n",
    "    full_size_image = image.img_to_array(full_size_image)\n",
    "    full_size_image /= 255\n",
    "#     x = 0.2\n",
    "    x = 0.4\n",
    "    avg_cols = np.mean(mask, axis=0)\n",
    "    more_than_x = avg_cols > x\n",
    "    cropped = full_size_image[:, more_than_x]\n",
    "    \n",
    "#     plt.imshow(full_size_image)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.imshow(cropped)\n",
    "#     plt.show()\n",
    "    return np.array(cropped*255, dtype=np.uint8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_image_mask(file_name, mask):\n",
    "    # this method multiplies the mask with the image, which results in a background of zeros\n",
    "    org_image = image.load_img(file_name)\n",
    "    \n",
    "    # resize the mask to match the original image size using interpolation\n",
    "    img_width = org_image.width\n",
    "    img_height = org_image.height\n",
    "    mask = interpolation.zoom(mask, [img_height/mask.shape[0], img_width/mask.shape[1]])\n",
    "    \n",
    "    org_image = image.img_to_array(org_image)\n",
    "    org_image /= 255\n",
    "    \n",
    "    discrete_mask = mask > 0.5 # set the mask to 0s and 1s\n",
    "    \n",
    "    return np.array(discrete_mask[:,:,np.newaxis] * org_image * 255, dtype=np.uint8) # newaxis: broadcast mask over RGB dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_image_background_zero(file_name, mask):\n",
    "    # this method sets all discovered background pixels to zero by using the method from \"crop images\", which only handles whole columns;\n",
    "    # this counteracts artefacts, which are produced by the \"detect Trunk\" network i.e. sometimes it predicts zero in the middle of the trunk...\n",
    "    # this method makes sure that nothing important is set to zero\n",
    "    org_image = image.load_img(file_name)\n",
    "    \n",
    "    # resize the mask to match the original image size using interpolation\n",
    "    img_width = org_image.width\n",
    "    img_height = org_image.height\n",
    "    mask = interpolation.zoom(mask, [img_height/mask.shape[0], img_width/mask.shape[1]])\n",
    "    \n",
    "    # set columns to zero, which have an avg of less than x%\n",
    "    org_image = image.img_to_array(org_image)\n",
    "    org_image /= 255\n",
    "    x = 0.5\n",
    "    avg_cols = np.mean(mask, axis=0)\n",
    "    less_than_x = avg_cols < x\n",
    "    org_image[:, less_than_x] = 0\n",
    "        \n",
    "    return np.array(org_image*255, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(folder_path):\n",
    "    new_subdir = subdir.replace(folder_path, save_masks_path)\n",
    "    new_cropped_subdir = subdir.replace(folder_path, save_cropped_path)\n",
    "    new_multiplied_subdir = subdir.replace(folder_path, save_multiplied_path)\n",
    "    \n",
    "    for file in files:\n",
    "        file_name = os.path.join(subdir, file)\n",
    "        \n",
    "        # load and preprocess image\n",
    "        sample_image = image.load_img(file_name, target_size=(HEIGHT, WIDTH))\n",
    "        sample_image = image.img_to_array(sample_image)\n",
    "        sample_image /= 255\n",
    "        \n",
    "        # predict mask and transform it to an image\n",
    "        pred = model.predict(sample_image[tf.newaxis, ...])\n",
    "        \n",
    "        #-------------------------------\n",
    "        # uncomment this, if you want to save the masks too\n",
    "        # save predicted mask to a new directory\n",
    "        mask = np.array(create_mask(pred), dtype=np.uint8)\n",
    "        img = Image.fromarray(mask, 'RGB')\n",
    "        if not os.path.exists(new_subdir):\n",
    "            os.makedirs(new_subdir)\n",
    "        img.save(file_name.replace(folder_path, save_masks_path))\n",
    "        \n",
    "        #-------------------------------\n",
    "        # crop images according to their mask \n",
    "        cropped = crop_image(file_name, pred[0,:,:,0])\n",
    "        \n",
    "        # save the cropped versions of the images to a new directory\n",
    "        cropped_img = Image.fromarray(cropped, 'RGB')\n",
    "        if not os.path.exists(new_cropped_subdir):\n",
    "            os.makedirs(new_cropped_subdir)\n",
    "        cropped_img.save(file_name.replace(folder_path, save_cropped_path))\n",
    "        \n",
    "        #-------------------------------\n",
    "#         # multiply image and mask\n",
    "# #         mult_image = multiply_image_mask(file_name, pred[0,:,:,0])\n",
    "#         # set background to zero; use this method to only set the images left and right columns to zero\n",
    "#         mult_image = set_image_background_zero(file_name, pred[0,:,:,0])\n",
    "#         # save the new image to a new directory\n",
    "#         mult_image = Image.fromarray(mult_image, 'RGB')\n",
    "#         if not os.path.exists(new_multiplied_subdir):\n",
    "#             os.makedirs(new_multiplied_subdir)\n",
    "#         mult_image.save(file_name.replace(folder_path, save_multiplied_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
