{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from 'D:\\\\drive\\\\MyDriveBackup\\\\9.Semester\\\\Masterarbeit\\\\masterarbeit - git\\\\Käferbäume\\\\Unet detect trees\\\\model.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload  # Python 3.4+ only.\n",
    "import data\n",
    "import model as model_functions\n",
    "\n",
    "reload(data)\n",
    "reload(model_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 256#128 #256\n",
    "HEIGHT = 256#128 #256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gini\\Anaconda3\\envs\\masterarbeit 2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = unet(input_size=(WIDTH,HEIGHT,3), nr_classes=len(COLOR_DICT))\n",
    "# model.load_weights('../../../Models/detect-tree/multi classes 128 - 256/4th-run-weights-improvement-20-0.0544.h5')\n",
    "model.load_weights('../../../Models/detect-tree/3rd-run-128-256-weights-improvement-18-0.0959.h5') # new\n",
    "\n",
    "# load_model('../../../Models/detect-tree/multi classes 128 - 256/4th-run-weights-improvement-20-0.0544.h5', custom_objects={'softMaxAxis1': softMaxAxis1, 'mean_io_u_13': tf.keras.metrics.MeanIoU})#, 'mean_io_u_13': tf.keras.metrics.MeanIoU, 'MeanIoU': tf.keras.metrics.MeanIoU})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 1024) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 1024) 0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 256 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 128 147584      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 128 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 32) 18464       conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 2)  66          conv2d_23[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,050,210\n",
      "Trainable params: 31,050,210\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process all images in a folder + subfolders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../../../Data/Borkenkaefer/data\"\n",
    "save_masks_path = \"../../../Data/Borkenkaefer/data_trunc_detected_masks\"\n",
    "save_cropped_path = \"../../../Data/Borkenkaefer/data_trunc_detected_cropped\"\n",
    "save_multiplied_path = \"../../../Data/Borkenkaefer/data_trunc_detected_multiplied\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = np.argmax(pred_mask, axis=-1)\n",
    "#     pred_mask = pred_mask[..., np.newaxis]\n",
    "    color_label_matrix = data.get_color_label_matrix(pred_mask[0])\n",
    "    return color_label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import interpolation\n",
    "\n",
    "def crop_image(file_name, mask):\n",
    "    # this method crops left and right from the image such that only the trunk is left\n",
    "    full_size_image = image.load_img(file_name)\n",
    "    \n",
    "    # resize the mask to match the original image size using interpolation\n",
    "    img_width = full_size_image.width\n",
    "    img_height = full_size_image.height\n",
    "    mask = interpolation.zoom(mask, [img_height/mask.shape[0], img_width/mask.shape[1]])\n",
    "    \n",
    "    # keep columns, which have an avg of more than x%\n",
    "    full_size_image = image.img_to_array(full_size_image)\n",
    "    full_size_image /= 255\n",
    "    x = 0.2\n",
    "    avg_cols = np.mean(mask, axis=0)\n",
    "    more_than_x = avg_cols > x\n",
    "    cropped = full_size_image[:, more_than_x]\n",
    "    \n",
    "#     plt.imshow(full_size_image)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.imshow(cropped)\n",
    "#     plt.show()\n",
    "    return np.array(cropped*255, dtype=np.uint8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_image_mask(file_name, mask):\n",
    "    # this method multiplies the mask with the image, which results in a background of zeros\n",
    "    org_image = image.load_img(file_name)\n",
    "    \n",
    "    # resize the mask to match the original image size using interpolation\n",
    "    img_width = org_image.width\n",
    "    img_height = org_image.height\n",
    "    mask = interpolation.zoom(mask, [img_height/mask.shape[0], img_width/mask.shape[1]])\n",
    "    \n",
    "    org_image = image.img_to_array(org_image)\n",
    "    org_image /= 255\n",
    "    \n",
    "    discrete_mask = mask > 0.5 # set the mask to 0s and 1s\n",
    "    \n",
    "    return np.array(discrete_mask[:,:,np.newaxis] * org_image * 255, dtype=np.uint8) # newaxis: broadcast mask over RGB dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_image_background_zero(file_name, mask):\n",
    "    # this method sets all discovered background pixels to zero by using the method from \"crop images\", which only handles whole columns;\n",
    "    # this counteracts artefacts, which are produced by the \"detect Trunk\" network i.e. sometimes it predicts zero in the middle of the trunk...\n",
    "    # this method makes sure that nothing important is set to zero\n",
    "    org_image = image.load_img(file_name)\n",
    "    \n",
    "    # resize the mask to match the original image size using interpolation\n",
    "    img_width = org_image.width\n",
    "    img_height = org_image.height\n",
    "    mask = interpolation.zoom(mask, [img_height/mask.shape[0], img_width/mask.shape[1]])\n",
    "    \n",
    "    # set columns to zero, which have an avg of less than x%\n",
    "    org_image = image.img_to_array(org_image)\n",
    "    org_image /= 255\n",
    "    x = 0.2\n",
    "    avg_cols = np.mean(mask, axis=0)\n",
    "    less_than_x = avg_cols < x\n",
    "    org_image[:, less_than_x] = 0\n",
    "        \n",
    "    return np.array(org_image*255, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Gini\\Anaconda3\\envs\\masterarbeit 2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-36-6c50da3ea11e>\", line 52, in <module>\n",
      "    plt.imshow(set_image_background_zero(file_name, pred[0,:,:,0]))\n",
      "  File \"<ipython-input-34-c7219d55b50b>\", line 9, in set_image_background_zero\n",
      "    mask = interpolation.zoom(mask, [img_height/mask.shape[0], img_width/mask.shape[1]])\n",
      "  File \"C:\\Users\\Gini\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\ndimage\\interpolation.py\", line 595, in zoom\n",
      "    _nd_image.zoom_shift(filtered, zoom, None, output, order, mode, cval)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Gini\\Anaconda3\\envs\\masterarbeit 2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Gini\\Anaconda3\\envs\\masterarbeit 2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Gini\\Anaconda3\\envs\\masterarbeit 2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Gini\\Anaconda3\\envs\\masterarbeit 2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Gini\\Anaconda3\\envs\\masterarbeit 2\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Gini\\Anaconda3\\envs\\masterarbeit 2\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Gini\\Anaconda3\\envs\\masterarbeit 2\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Gini\\Anaconda3\\envs\\masterarbeit 2\\lib\\inspect.py\", line 734, in getmodule\n",
      "    f = module.__file__\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(folder_path):\n",
    "    new_subdir = subdir.replace(folder_path, save_masks_path)\n",
    "    new_cropped_subdir = subdir.replace(folder_path, save_cropped_path)\n",
    "    new_multiplied_subdir = subdir.replace(folder_path, save_multiplied_path)\n",
    "    \n",
    "    for file in files:\n",
    "        file_name = os.path.join(subdir, file)\n",
    "        \n",
    "        # load and preprocess image\n",
    "        sample_image = image.load_img(file_name, target_size=(HEIGHT, WIDTH))\n",
    "        sample_image = image.img_to_array(sample_image)\n",
    "        sample_image /= 255\n",
    "        \n",
    "        # predict mask and transform it to an image\n",
    "        pred = model.predict(sample_image[tf.newaxis, ...])\n",
    "        \n",
    "        #-------------------------------\n",
    "#         # uncomment this, if you want to save the masks too\n",
    "#         # save predicted mask to a new directory\n",
    "#         mask = np.array(create_mask(pred), dtype=np.uint8)\n",
    "#         img = Image.fromarray(mask, 'RGB')\n",
    "#         if not os.path.exists(new_subdir):\n",
    "#             os.makedirs(new_subdir)\n",
    "#         img.save(file_name.replace(folder_path, save_masks_path))\n",
    "        \n",
    "        #-------------------------------\n",
    "#         # crop images according to their mask \n",
    "#         cropped = crop_image(file_name, pred[0,:,:,0])\n",
    "        \n",
    "#         # save the cropped versions of the images to a new directory\n",
    "#         cropped_img = Image.fromarray(cropped, 'RGB')\n",
    "#         if not os.path.exists(new_cropped_subdir):\n",
    "#             os.makedirs(new_cropped_subdir)\n",
    "#         cropped_img.save(file_name.replace(folder_path, save_cropped_path))\n",
    "        \n",
    "        #-------------------------------\n",
    "#         # multiply image and mask\n",
    "#         mult_image = multiply_image_mask(file_name, pred[0,:,:,0])\n",
    "#         # save the new image to a new directory\n",
    "#         mult_image = Image.fromarray(mult_image, 'RGB')\n",
    "#         if not os.path.exists(new_multiplied_subdir):\n",
    "#             os.makedirs(new_multiplied_subdir)\n",
    "#         mult_image.save(file_name.replace(folder_path, save_multiplied_path))\n",
    "\n",
    "        plt.imshow(set_image_background_zero(file_name, pred[0,:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
